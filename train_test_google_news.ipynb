{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "google_news_numpy = numpy.load('F:/VIGHNESH/Cognitive_Computing/Final_Project/google-news-numpy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "google_news_numpy = numpy.float32(google_news_numpy)\n",
    "print(google_news_numpy.shape)\n",
    "length_vocab, embedding_size = google_news_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len_head = 25\n",
    "max_len_desc = 50\n",
    "max_length = max_len_head + max_len_desc\n",
    "rnn_layers = 4\n",
    "rnn_size = 600\n",
    "# first 40 numebers from hidden layer output used for\n",
    "# simple context calculation\n",
    "activation_rnn_size = 50\n",
    "\n",
    "empty_tag_location = 0\n",
    "eos_tag_location = 1\n",
    "unknown_tag_location = 2\n",
    "learning_rate = 1e-4\n",
    "\n",
    "#minimum headline should be genrated\n",
    "min_head_line_gen = 10\n",
    "dont_repeat_word_in_last = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "\n",
    "# TODO: look at mask zero flag\n",
    "rnn_model.add(\n",
    "        Embedding(\n",
    "                length_vocab, embedding_size,\n",
    "                input_length=max_length,\n",
    "                weights=[google_news_numpy], mask_zero=True,\n",
    "                name='embedding_layer'\n",
    "        )\n",
    ")\n",
    "\n",
    "for i in range(rnn_layers):\n",
    "    lstm = LSTM(rnn_size, return_sequences=True,\n",
    "        name='lstm_layer_%d' % (i + 1)\n",
    "    )\n",
    "    rnn_model.add(lstm)\n",
    "    # No drop out added !\n",
    "'''\n",
    "model.add(Lambda(self.simple_context,\n",
    "                mask=lambda inputs, mask: mask[:, max_len_desc:],\n",
    "                output_shape=self.output_shape_simple_context_layer,\n",
    "                name='simple_context_layer'))\n",
    "\n",
    "'''\n",
    "\n",
    "rnn_model.add(TimeDistributed(Dense(length_vocab,\n",
    "                        name='time_distributed_layer')))\n",
    "        \n",
    "rnn_model.add(Activation('softmax', name='activation_layer'))\n",
    "        \n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "K.set_value(rnn_model.optimizer.lr, np.float32(learning_rate))\n",
    "print (rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

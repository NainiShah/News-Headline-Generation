{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('F:/VIGHNESH/Cognitive Computing/Final Project/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_load_specials', '_save_specials', '_smart_save', 'accuracy', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_pairs', 'get_keras_embedding', 'get_vector', 'index2entity', 'index2word', 'init_sims', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'rank', 'save', 'save_word2vec_format', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_matrix', 'syn0', 'syn0norm', 'vector_size', 'vectors', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than', 'wv']\n"
     ]
    }
   ],
   "source": [
    "print([method for method in dir(model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 300\n"
     ]
    }
   ],
   "source": [
    "print(len(model.vectors), model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(model):\n",
    "    \"\"\"Make dataset from pre-trained Word2Vec model.\n",
    "    Paramters\n",
    "    ---------\n",
    "    model: gensim.models.word2vec.Word2Vec\n",
    "        pre-traind Word2Vec model as gensim object.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray((vocabrary size, vector size))\n",
    "        Sikitlearn's X format.\n",
    "    \"\"\"\n",
    "    V = model.index2word\n",
    "    X = np.zeros((len(V), model.vector_size))\n",
    "\n",
    "    for index, word in enumerate(V):\n",
    "        X[index, :] += model[word]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_list = make_dataset(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.12915039e-03  -8.96453857e-04   3.18527222e-04 ...,  -1.56402588e-03\n",
      "   -1.23023987e-04  -8.63075256e-05]\n",
      " [  7.03125000e-02   8.69140625e-02   8.78906250e-02 ...,  -4.76074219e-02\n",
      "    1.44653320e-02  -6.25000000e-02]\n",
      " [ -1.17797852e-02  -4.73632812e-02   4.46777344e-02 ...,   7.12890625e-02\n",
      "   -3.49121094e-02   2.41699219e-02]\n",
      " ..., \n",
      " [ -1.96533203e-02  -9.08203125e-02  -1.94091797e-02 ...,  -1.63574219e-02\n",
      "   -1.34277344e-02   4.66308594e-02]\n",
      " [  3.27148438e-02  -3.22265625e-02   3.61328125e-02 ...,  -8.85009766e-03\n",
      "    2.69775391e-02   1.90429688e-02]\n",
      " [  4.51660156e-02  -4.51660156e-02  -3.93676758e-03 ...,   7.95898438e-02\n",
      "    7.22656250e-02   1.30004883e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(google_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.save('F:/VIGHNESH/Cognitive Computing/Final Project/google-news-numpy.npy',google_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "in\n",
      "for\n",
      "that\n",
      "is\n",
      "on\n",
      "##\n",
      "The\n",
      "with\n",
      "said\n",
      "was\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(model.vocab):\n",
    "    if(i > 10):\n",
    "        break\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
